# V20 Vision-Grounded VLM Method Report
======================================================================

## Method Overview

**V20 Vision-Grounded VLM-Guided Granularity Selection**

Key Features:
- Vision-Language Model: Qwen2.5-VL-3B-Instruct
- Visual Grounding: VLM sees actual image
- Scene Context: Full scene graph (objects + relationships + bboxes)
- Two-Stage Selection: Mid-level first, then coarse-level
- Vision-Aware Reasoning: Considers visual features for semantic decisions
- Fallback: V7 adaptive rules if VLM fails

## Performance Statistics

Total objects processed: 19
VLM success: 11/19 (57.9%)
Fallback to V7 rules: 7/19 (36.8%)

## Vision-Grounded Reasoning Examples

Sample VLM reasoning with visual grounding:

1. **shoe** → footwear (mid) → object (coarse)
   Reasoning: Visible shoes worn by person performing skateboarding trick

2. **ramp** → artifact (mid) → object (coarse)
   Reasoning: Ramp is a man-made structure used for skateboarding

3. **bicycle** → conveyance (mid) → object (coarse)
   Reasoning: Bicycle is a mode of transportation used by people in the image.

4. **skateboard** → instrumentality (mid) → object (coarse)
   Reasoning: Skateboard is a piece of equipment used for performing tricks in skate parks.

5. **hair** → natural object (mid) → object (coarse)
   Reasoning: Visible hair on the person's head

6. **grass** → plant (mid) → object (coarse)
   Reasoning: Grass is a living plant visible in the image.

7. **edge** → region (mid) → object (coarse)
   Reasoning: The 'edge' is a visible boundary or limit, which can be considered an object within the context of the image.

8. **bench** → furniture (mid) → object (coarse)
   Reasoning: Visible outdoor seating area made of concrete

9. **leg** → body part (mid) → physical entity (coarse)
   Reasoning: Visible human leg in mid-air during a skateboarding trick

10. **person** → living thing (mid) → physical entity (coarse)
   Reasoning: The image shows a person wearing a green shirt and blue jeans, which is a living being.

## Comparison with V8.1

V8.1 (Text-Only LLM):
- Uses Qwen3-0.6B text-only LLM
- Scene context: text descriptions only
- No visual grounding

V20 (Vision-Language Model):
- Uses Qwen2.5-VL-3B vision-language model
- Scene context: text + actual image
- Visual grounding: VLM can see objects and their visual features
- Expected improvement: Better semantic decisions for visually-ambiguous objects

